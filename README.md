# kip-parallel-OpenMP
Parallelized version of Kernel Image Processing, i.e. kernel filtering applied to 2D images, with OpenMP.







## Processo di parallelizzazione

Parallelizzare un programma sequenziale non significa solo ‚Äúaggiungere thread‚Äù, ma richiede un percorso metodico per evitare false parallelizzazioni, o addirittura rallentamenti, capire dove concentrare sforzi e analisi col fine di ottenere miglioramenti, e capire **quanto bene l‚Äôalgoritmo** sia stato parallelizzato e quanto si possa ancora fare. A tal proposito, il workflow seguito in questo lavoro pu√≤ essere cos√¨ riassunto:
1. **Profiling del codice sequenziale** (e.g. tramite VTune) per individuare dove intervenire:
   * Identificare gli *hotspot*, i.e. funzioni che consumano pi√π tempo.
   * Capire se il collo di bottiglia √® CPU, memoria, o I/O.
2. **Parallelizzazione incrementale**:
   * Riconoscere sezioni parallele
   * Privatizzare le variabili
   * Scegliere scheduling
3. **Analisi della scalabilit√† teorica**:
   * **Legge di Amdahl**: limite massimo dato dalla frazione sequenziale.
   * **Legge di Gustafson**: crescita del problema rende pi√π favorevole il parallelismo.
4. **Profiling del codice parallelo**:
   * Localizzare overhead
   * Riconoscere colli di bottiglia (memoria, load balance, etc)

In particolare, la profilazione deve essere integrata con: 
* Lo **strong scaling**: verificare riduzione del tempo di esecuzione fissando il problema e aumentando i core.
* Il **weak scaling**: misura come varia il tempo quando la dimensione del problema cresce proporzionalmente ai core.

Queste analisi sono fondamentali perch√© consentono di:
1. **Quantificare l‚Äôefficacia della parallelizzazione** (dove conviene spingersi con il numero di core).
2. **Individuare colli di bottiglia** (memoria, sincronizzazioni, comunicazioni).
3. **Guidare lo sviluppo**: capire se conviene lavorare su bilanciamento del carico, comunicazioni, o ridisegnare l‚Äôalgoritmo.

### Strong Scaling

#### Definizione

* Problema fissato, core crescenti.
* Metriche principali:

  * **Speedup**: $S(p) = \frac{T(1)}{T(p)}$.
  * **Efficienza strong**: $E(p) = \frac{S(p)}{p}$.

#### Interpretazione dei grafici

* **Tempo vs core**: ci si aspetta una decrescita quasi iperbolica ($T(p) \approx T(1)/p$).
* **Speedup vs core**: la curva reale dovrebbe avvicinarsi alla diagonale ideale ($S(p) = p$).
* **Efficienza strong vs core**: tipicamente cala oltre una certa soglia (limiti di Amdahl).

#### Utilit√† nel processo

* Serve a capire **quanto un problema fisso beneficia della parallelizzazione**.
* √à cruciale per applicazioni interattive o real-time, dove la dimensione del problema non pu√≤ crescere ma conta solo ridurre il tempo.

### Weak Scaling

#### Definizione

* Problema per core costante: raddoppio i core, raddoppio i dati.
* Metriche principali:

  * **Weak efficiency**: $E_w(p) = \frac{T(1)}{T(p)}$ (tempo atteso costante).
  * **Scaled speedup**: $S_w(p) = \frac{p \cdot T(1)}{T(p)}$.
  * **Throughput**: lavoro eseguito per unit√† di tempo (Mpix/s, FLOP/s‚Ä¶).

#### Interpretazione dei grafici

* **Tempo vs core**: ideale √® costante. Un aumento segnala overhead di comunicazione o memoria.
* **Weak efficiency**: ideale 100%. Accettabile ‚â• 80‚Äì90% in HPC.
* **Scaled speedup vs core**: dovrebbe seguire la diagonale $y = p$.
* **Throughput**: ideale cresce linearmente ($p \cdot \text{Throughput}_1$), quello reale tende a saturarsi.

#### Utilit√† nel processo

* Serve a capire se il programma pu√≤ **gestire problemi sempre pi√π grandi** su pi√π risorse.
* √à cruciale per simulazioni scientifiche, big data, deep learning.

   * Se l‚Äôefficienza crolla presto ‚áí overhead di sincronizzazione o parte sequenziale troppo pesante.
4. **Weak scaling**: verificare se l‚Äôapp regge problemi crescenti.
 Decidere il giusto numero di thread da utilizzare
   * Se l‚Äôefficienza cala ‚áí colli di bottiglia in memoria, comunicazioni, o load balancing.
5. **Analisi dei grafici**:

   * Se **throughput scala bene** ma **tempo non cala**, l‚Äôalgoritmo √® adatto a problemi grandi, non a tempi ridotti.
   * Se **strong scaling √® buono** ma **weak inefficiente**, l‚Äôalgoritmo gestisce bene problemi fissi ma non cresce bene.
   * Se entrambi sono scarsi ‚áí serve un redesign dell‚Äôalgoritmo.
6. **Iterazione**: ripetere profiling ‚Üí tuning ‚Üí scaling finch√© non si raggiunge un compromesso accettabile.










# üîπ Interpretazione congiunta dei grafici

Per non avere ridondanze:

* **Tempo medio** (strong) + **Throughput** (weak) danno la visione pratica: velocit√† e produttivit√†.
* **Efficienza** (sia strong che weak) √® utile per diagnosticare overhead nascosti.
* **Speedup** √® pi√π ‚Äúdidattico‚Äù ma meno utile se gi√† hai efficienza.

üëâ Quindi, in un report finale:

* tieni **Tempo vs core** e **Throughput vs core** come indicatori principali;
* usa **Efficienza** per discutere criticit√†;
* puoi omettere speedup se serve concisione.

---

# üîπ Conclusione

Un processo di parallelizzazione ottimale richiede **profiling accurato + analisi di strong/weak scaling**.

* Lo **strong scaling** ti dice se il programma pu√≤ diventare pi√π veloce.
* Il **weak scaling** ti dice se il programma pu√≤ affrontare problemi pi√π grandi.
* I grafici (tempo, efficienza, throughput) vanno letti congiuntamente per capire **se conviene scalare su pi√π core, se serve un redesign, o se il programma √® gi√† vicino al massimo teorico**.


